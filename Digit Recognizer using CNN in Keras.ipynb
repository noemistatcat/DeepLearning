{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## **1. Loading the Data and the Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Loading required packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## **2. Data Inspection and EDA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Our training data consists of 42,000 rows and 785 columns. Each row represents individual images. The first column is the \"label\" for the digit in the image, while the rest of the columns correspond to the pixels associated with the images.   "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 2.1 Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       785\n",
       "unique        1\n",
       "top       False\n",
       "freq        785\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "There are no missing values based on the initial data inspection. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 2.2 Examine the Distribution of the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of digit classes')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(train_data['label'])\n",
    "plt.title(\"Number of digit classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "From the plot it appears that the 10 digits have fairly similar counts and it relatively balanced. We can therefore prepare the data for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 3. Preparing the Data for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.1 Separating the Predictors from the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('label' , axis=1)\n",
    "y = train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.2 Normalizing the Data to Increase Model Efficency"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In this step we perform grayscale normalization on the features by dividing everything by 255. <br>This would help make the model run faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.3 Partitioning the Data into Train and Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "We split the data into test and training set to be able to get a sense of its performance in unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.4 Reshaping the data for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "This transformation is necessary to make the data shape suitable for the CNN prediction in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, 28, 28, 1).astype('float32')\n",
    "X_test = X_test.values.reshape(-1, 28, 28, 1).astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 28, 28, 1)\n",
      "(4200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.5 One-Hot Encoding of the Target Variable "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The outcome (digit labels) is categorical format hence the need to transform them into one-hot vectors containing 1 or 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 10)\n",
      "(4200, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 4. Prediction Through Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3965184   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,118,154\n",
      "Trainable params: 4,118,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setting up the neural network model\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation= 'relu',input_shape=(IMG_ROWS,IMG_COLS,1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32,(3,3),activation= 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32,(3,3),activation= 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation= 'relu'))\n",
    "model.add(Dense(256,activation= 'relu'))\n",
    "model.add(Dense(256,activation= 'relu'))\n",
    "model.add(Dense(NUM_CLASSES,activation= 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30240 samples, validate on 7560 samples\n",
      "Epoch 1/10\n",
      "30240/30240 [==============================] - 82s 3ms/step - loss: 0.2598 - accuracy: 0.9183 - val_loss: 0.0885 - val_accuracy: 0.9716\n",
      "Epoch 2/10\n",
      "30240/30240 [==============================] - 80s 3ms/step - loss: 0.0970 - accuracy: 0.9706 - val_loss: 0.0679 - val_accuracy: 0.9788\n",
      "Epoch 3/10\n",
      "30240/30240 [==============================] - 80s 3ms/step - loss: 0.0704 - accuracy: 0.9775 - val_loss: 0.0632 - val_accuracy: 0.9836\n",
      "Epoch 4/10\n",
      "30240/30240 [==============================] - 80s 3ms/step - loss: 0.0634 - accuracy: 0.9808 - val_loss: 0.0568 - val_accuracy: 0.9837\n",
      "Epoch 5/10\n",
      "30240/30240 [==============================] - 80s 3ms/step - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.0532 - val_accuracy: 0.9854\n",
      "Epoch 6/10\n",
      " 6720/30240 [=====>........................] - ETA: 1:00 - loss: 0.0463 - accuracy: 0.9866"
     ]
    }
   ],
   "source": [
    "# Compiling and fitting the model\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 505us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04331282474570409, 0.9892857074737549]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model for out of sample performance\n",
    "\n",
    "model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 5. Predicting the Test Data for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the data for CNN\n",
    "\n",
    "test_data_OH = test_data.values.reshape(-1, 28, 28, 1).astype('float32')\n",
    "print(test_data_OH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Dataset\n",
    "\n",
    "predictions = model.predict(test_data_OH, batch_size = 32)\n",
    "predictions = np.array([np.argmax(row) for row in predictions])\n",
    "submission = pd.DataFrame({'ImageId' : np.arange(1,len(test_data)+1), 'Label' : predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_predictions_12May2020.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "to be continued"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "to add:\n",
    "\n",
    "Validation plots to assess overfitting  <br>\n",
    "Examination of the wrongly-classified images  <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
